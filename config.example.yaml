# Agentic Dataset Generation Configuration

# API Configuration
api:
  provider: "openrouter" # API provider (e.g., "openrouter")
  base_url: "https://openrouter.ai/api/v1/chat/completions" # API endpoint
  model: "anthropic/claude-3.5-sonnet" # Model to use for generation
  api_key: "your-api-key-here" # API key (can also be set via OPENROUTER_API_KEY env var)
  api_key_env: "OPENROUTER_API_KEY" # Optional: override the env var name
  searxng_url: "https://searxng.gptbox.dev" # Custom SearXNG instance URL

# Prompts Configuration
prompts:
  source: "prompts.txt" # Path to prompts file relative to repo root
  limit: null # Optional: limit number of prompts to process (null/0 = all)
  shuffle: false # Whether to shuffle prompts before processing

# Workspace Configuration
workspace:
  base_dir: "sandbox" # Directory for agent workspaces, relative to repo root
  cleanup: true # Whether to delete workspace after successful processing
  preserve_on_error: true # Keep workspace if processing fails

# Agent Configuration
agent:
  max_turns: 50 # Maximum conversation turns per prompt
  tools_enabled:
    - read_file
    - write_file
    - edit_file
    - list_directory
    - search_code
    - run_command
    - web_search

# Output Configuration
output:
  dataset_file: "datasets/agentic_dataset.jsonl" # Target dataset file relative to repo root
  error_dataset_file: "datasets/agentic_dataset_errors.jsonl" # Optional: failed sessions only
  append_mode: true # Append to dataset (false = overwrite)

# Processing Configuration
processing:
  concurrency: 1 # Number of prompts to process concurrently
  resume: true # Resume from existing dataset file
